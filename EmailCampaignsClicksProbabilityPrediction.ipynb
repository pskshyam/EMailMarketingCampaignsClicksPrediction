{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Lord of the Machines - Data Science Hackathon\n",
    "\n",
    "<b>Problem Statement</b><br>\n",
    "Email Marketing is still the most successful marketing channel and the essential element of any digital marketing strategy. Marketers spend a lot of time in writing that perfect email, labouring over each word, catchy layouts on multiple devices to get them best in-industry open rates & click rates.\n",
    "\n",
    "How can I build my campaign to increase the click-through rates of email? - a question that is often heard when marketers are creating their email marketing plans.\n",
    "\n",
    "Can we optimize our email marketing campaigns with Data Science?\n",
    "\n",
    "It's time to unlock marketing potential and build some exceptional data-science products for email marketing.\n",
    "\n",
    "Analytics Vidhya sends out marketing emailers for various events such as conferences, hackathons, etc. We have provided a sample of user-email interaction data from July 2017 to December 2017. You are required to predict the click probability of links inside a mailer for email campaigns from January 2018 to March 2018.\n",
    "\n",
    "<b>Evaluation Metric</b><br>\n",
    "The evaluation metric for this competition is AUC-ROC score.\n",
    "\n",
    "<b>Datasets:</b><br>\n",
    "We are provided with 3 datasets:\n",
    "1. campaign_data.csv -  Contains the features related to 52 email Campaigns\n",
    "2. train.csv - Contains the click and open information for each user corresponding to given campaign id (Jul 17 - Dec 17)\n",
    "3. test.csv - Contains the user and campaigns for which is_click needs to be predicted (Jan 18 - Mar 18)\n",
    "\n",
    "For more information on this hackathon and for downloading datasets:<br>\n",
    "https://datahack.analyticsvidhya.com/contest/lord-of-the-machines/?utm_source=sendinblue&utm_campaign=Lord_Of_The_Machines__Go_live&utm_medium=email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import basic necessary datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell #To print multiple outputs\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>communication_type</th>\n",
       "      <th>total_links</th>\n",
       "      <th>no_of_internal_links</th>\n",
       "      <th>no_of_images</th>\n",
       "      <th>no_of_sections</th>\n",
       "      <th>email_body</th>\n",
       "      <th>subject</th>\n",
       "      <th>email_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>Newsletter</td>\n",
       "      <td>67</td>\n",
       "      <td>61</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>Dear AVians,\\r\\n \\r\\nWe are shaping up a super...</td>\n",
       "      <td>Sneak Peek: A look at the emerging data scienc...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7um44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Upcoming Events</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear AVians,\\r\\n \\r\\nAre your eager to know wh...</td>\n",
       "      <td>[July] Data Science Expert Meetups &amp; Competiti...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7up0e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>Conference</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Early Bird Pricing Till August 07  Save upto ...</td>\n",
       "      <td>Last chance to convince your boss before the E...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7usym...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   campaign_id communication_type  total_links  no_of_internal_links  \\\n",
       "0           29         Newsletter           67                    61   \n",
       "1           30    Upcoming Events           18                    14   \n",
       "2           31         Conference           15                    13   \n",
       "\n",
       "   no_of_images  no_of_sections  \\\n",
       "0            12               3   \n",
       "1             7               1   \n",
       "2             5               1   \n",
       "\n",
       "                                          email_body  \\\n",
       "0  Dear AVians,\\r\\n \\r\\nWe are shaping up a super...   \n",
       "1  Dear AVians,\\r\\n \\r\\nAre your eager to know wh...   \n",
       "2  Early Bird Pricing Till August 07  Save upto ...   \n",
       "\n",
       "                                             subject  \\\n",
       "0  Sneak Peek: A look at the emerging data scienc...   \n",
       "1  [July] Data Science Expert Meetups & Competiti...   \n",
       "2  Last chance to convince your boss before the E...   \n",
       "\n",
       "                                           email_url  \n",
       "0  http://r.newsletters.analyticsvidhya.com/7um44...  \n",
       "1  http://r.newsletters.analyticsvidhya.com/7up0e...  \n",
       "2  http://r.newsletters.analyticsvidhya.com/7usym...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1023191, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>send_date</th>\n",
       "      <th>is_open</th>\n",
       "      <th>is_click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42_14051</td>\n",
       "      <td>14051</td>\n",
       "      <td>42</td>\n",
       "      <td>01-09-2017 19:55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52_134438</td>\n",
       "      <td>134438</td>\n",
       "      <td>52</td>\n",
       "      <td>02-11-2017 12:53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33_181789</td>\n",
       "      <td>181789</td>\n",
       "      <td>33</td>\n",
       "      <td>24-07-2017 15:15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44_231448</td>\n",
       "      <td>231448</td>\n",
       "      <td>44</td>\n",
       "      <td>05-09-2017 11:36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29_185580</td>\n",
       "      <td>185580</td>\n",
       "      <td>29</td>\n",
       "      <td>01-07-2017 18:01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  user_id  campaign_id         send_date  is_open  is_click\n",
       "0   42_14051    14051           42  01-09-2017 19:55        0         0\n",
       "1  52_134438   134438           52  02-11-2017 12:53        0         0\n",
       "2  33_181789   181789           33  24-07-2017 15:15        0         0\n",
       "3  44_231448   231448           44  05-09-2017 11:36        0         0\n",
       "4  29_185580   185580           29  01-07-2017 18:01        0         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(773858, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>send_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63_122715</td>\n",
       "      <td>63</td>\n",
       "      <td>122715</td>\n",
       "      <td>01-02-2018 22:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56_76206</td>\n",
       "      <td>56</td>\n",
       "      <td>76206</td>\n",
       "      <td>02-01-2018 08:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57_96189</td>\n",
       "      <td>57</td>\n",
       "      <td>96189</td>\n",
       "      <td>05-01-2018 18:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56_166917</td>\n",
       "      <td>56</td>\n",
       "      <td>166917</td>\n",
       "      <td>02-01-2018 08:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56_172838</td>\n",
       "      <td>56</td>\n",
       "      <td>172838</td>\n",
       "      <td>02-01-2018 08:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  campaign_id  user_id         send_date\n",
       "0  63_122715           63   122715  01-02-2018 22:35\n",
       "1   56_76206           56    76206  02-01-2018 08:15\n",
       "2   57_96189           57    96189  05-01-2018 18:25\n",
       "3  56_166917           56   166917  02-01-2018 08:15\n",
       "4  56_172838           56   172838  02-01-2018 08:12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(773858, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63_122715</td>\n",
       "      <td>0.516037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56_76206</td>\n",
       "      <td>0.535007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57_96189</td>\n",
       "      <td>0.481492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56_166917</td>\n",
       "      <td>0.527826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56_172838</td>\n",
       "      <td>0.525384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  is_click\n",
       "0  63_122715  0.516037\n",
       "1   56_76206  0.535007\n",
       "2   57_96189  0.481492\n",
       "3  56_166917  0.527826\n",
       "4  56_172838  0.525384"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the campaign, train and test csv files provided and view the data\n",
    "campaign = pd.read_csv('campaign_data.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample = pd.read_csv('sample_submission.csv')\n",
    "campaign.shape\n",
    "campaign.head(3)\n",
    "train.shape\n",
    "train.head()\n",
    "test.shape\n",
    "test.head()\n",
    "sample.shape\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023191, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(773858, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>send_date</th>\n",
       "      <th>is_open</th>\n",
       "      <th>is_click</th>\n",
       "      <th>communication_type</th>\n",
       "      <th>total_links</th>\n",
       "      <th>no_of_internal_links</th>\n",
       "      <th>no_of_images</th>\n",
       "      <th>no_of_sections</th>\n",
       "      <th>email_body</th>\n",
       "      <th>subject</th>\n",
       "      <th>email_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42_14051</td>\n",
       "      <td>14051</td>\n",
       "      <td>42</td>\n",
       "      <td>01-09-2017 19:55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Newsletter</td>\n",
       "      <td>88</td>\n",
       "      <td>79</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>September Newsletter\\r\\n \\r\\nDear AVians,\\r\\n ...</td>\n",
       "      <td>[September] Exciting days ahead with DataHack ...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7v3rd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52_134438</td>\n",
       "      <td>134438</td>\n",
       "      <td>52</td>\n",
       "      <td>02-11-2017 12:53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Newsletter</td>\n",
       "      <td>67</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>November Newsletter\\r\\n \\r\\nDear AVians,\\r\\n \\...</td>\n",
       "      <td>[Newsletter] Stage for DataHack Summit 2017 is...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7vtb2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33_181789</td>\n",
       "      <td>181789</td>\n",
       "      <td>33</td>\n",
       "      <td>24-07-2017 15:15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Others</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fireside Chat with DJ Patil - the master is he...</td>\n",
       "      <td>[Delhi NCR] Fireside Chat with DJ Patil, Forme...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7uvlg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  user_id  campaign_id         send_date  is_open  is_click  \\\n",
       "0   42_14051    14051           42  01-09-2017 19:55        0         0   \n",
       "1  52_134438   134438           52  02-11-2017 12:53        0         0   \n",
       "2  33_181789   181789           33  24-07-2017 15:15        0         0   \n",
       "\n",
       "  communication_type  total_links  no_of_internal_links  no_of_images  \\\n",
       "0         Newsletter           88                    79            13   \n",
       "1         Newsletter           67                    62            10   \n",
       "2             Others            7                     3             1   \n",
       "\n",
       "   no_of_sections                                         email_body  \\\n",
       "0               4  September Newsletter\\r\\n \\r\\nDear AVians,\\r\\n ...   \n",
       "1               4  November Newsletter\\r\\n \\r\\nDear AVians,\\r\\n \\...   \n",
       "2               1  Fireside Chat with DJ Patil - the master is he...   \n",
       "\n",
       "                                             subject  \\\n",
       "0  [September] Exciting days ahead with DataHack ...   \n",
       "1  [Newsletter] Stage for DataHack Summit 2017 is...   \n",
       "2  [Delhi NCR] Fireside Chat with DJ Patil, Forme...   \n",
       "\n",
       "                                           email_url  \n",
       "0  http://r.newsletters.analyticsvidhya.com/7v3rd...  \n",
       "1  http://r.newsletters.analyticsvidhya.com/7vtb2...  \n",
       "2  http://r.newsletters.analyticsvidhya.com/7uvlg...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge train and test datasets with campaign dataset on 'campaign_id' feature\n",
    "train_merged = pd.merge(train, campaign, on='campaign_id', how='left').reset_index(drop=True)\n",
    "test_merged = pd.merge(test, campaign, on='campaign_id', how='left').reset_index(drop=True)\n",
    "train_merged.shape\n",
    "test_merged.shape\n",
    "train_merged.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1023191 entries, 0 to 1023190\n",
      "Data columns (total 14 columns):\n",
      "id                      1023191 non-null object\n",
      "user_id                 1023191 non-null int64\n",
      "campaign_id             1023191 non-null int64\n",
      "send_date               1023191 non-null object\n",
      "is_open                 1023191 non-null int64\n",
      "is_click                1023191 non-null int64\n",
      "communication_type      1023191 non-null object\n",
      "total_links             1023191 non-null int64\n",
      "no_of_internal_links    1023191 non-null int64\n",
      "no_of_images            1023191 non-null int64\n",
      "no_of_sections          1023191 non-null int64\n",
      "email_body              1023191 non-null object\n",
      "subject                 1023191 non-null object\n",
      "email_url               1023191 non-null object\n",
      "dtypes: int64(8), object(6)\n",
      "memory usage: 109.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#Check datatypes of the features in train data\n",
    "train_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The feature 'send_date' is of type object which needs to be converted into datetime\n",
    "train_merged['send_date'] = pd.to_datetime(train_merged.send_date)\n",
    "test_merged['send_date'] = pd.to_datetime(test_merged.send_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Newsletter', 'Others', 'Upcoming Events', 'Conference',\n",
       "       'Corporate', 'Hackathon', 'Webinar'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['Newsletter', 'Upcoming Events', 'Hackathon', 'Corporate'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check unique communication types in train and test datasets\n",
    "train_merged.communication_type.unique()\n",
    "test_merged.communication_type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that communication types such as Others, Conference, Webinar are not present in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 5, 0, 1, 2, 6], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 3, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us encode the labels of communication types using sklearn.labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train_merged.communication_type = le.fit_transform(train_merged.communication_type)\n",
    "test_merged.communication_type = le.fit_transform(test_merged.communication_type)\n",
    "train_merged.communication_type.unique()\n",
    "test_merged.communication_type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets split the feature 'send_date' to gain more insights\n",
    "train_merged['day_of_week'] = train_merged['send_date'].dt.dayofweek\n",
    "train_merged['hour'] = train_merged['send_date'].dt.hour\n",
    "train_merged['day'] = train_merged['send_date'].dt.day\n",
    "train_merged['month'] = train_merged['send_date'].dt.month\n",
    "train_merged['IsWeekend'] = train_merged['day_of_week'].apply(lambda x : 0 if x==0 | x==6 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_merged['day_of_week'] = test_merged['send_date'].dt.dayofweek\n",
    "test_merged['hour'] = test_merged['send_date'].dt.hour\n",
    "test_merged['day'] = test_merged['send_date'].dt.day\n",
    "test_merged['month'] = test_merged['send_date'].dt.month\n",
    "test_merged['IsWeekend'] = test_merged['day_of_week'].apply(lambda x : 0 if x==0 | x==6 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_merged = pd.read_csv('train_merged.csv')\n",
    "test_merged = pd.read_csv('test_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>send_date</th>\n",
       "      <th>is_open</th>\n",
       "      <th>is_click</th>\n",
       "      <th>communication_type</th>\n",
       "      <th>total_links</th>\n",
       "      <th>no_of_internal_links</th>\n",
       "      <th>no_of_images</th>\n",
       "      <th>no_of_sections</th>\n",
       "      <th>email_body</th>\n",
       "      <th>subject</th>\n",
       "      <th>email_url</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>IsWeekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42_14051</td>\n",
       "      <td>14051</td>\n",
       "      <td>42</td>\n",
       "      <td>2017-01-09 19:55:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>79</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>September Newsletter\\r\\r\\n \\r\\r\\nDear AVians,\\...</td>\n",
       "      <td>[September] Exciting days ahead with DataHack ...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7v3rd...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52_134438</td>\n",
       "      <td>134438</td>\n",
       "      <td>52</td>\n",
       "      <td>2017-02-11 12:53:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>November Newsletter\\r\\r\\n \\r\\r\\nDear AVians,\\r...</td>\n",
       "      <td>[Newsletter] Stage for DataHack Summit 2017 is...</td>\n",
       "      <td>http://r.newsletters.analyticsvidhya.com/7vtb2...</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  user_id  campaign_id            send_date  is_open  is_click  \\\n",
       "0   42_14051    14051           42  2017-01-09 19:55:00        0         0   \n",
       "1  52_134438   134438           52  2017-02-11 12:53:00        0         0   \n",
       "\n",
       "   communication_type  total_links  no_of_internal_links  no_of_images  \\\n",
       "0                   3           88                    79            13   \n",
       "1                   3           67                    62            10   \n",
       "\n",
       "   no_of_sections                                         email_body  \\\n",
       "0               4  September Newsletter\\r\\r\\n \\r\\r\\nDear AVians,\\...   \n",
       "1               4  November Newsletter\\r\\r\\n \\r\\r\\nDear AVians,\\r...   \n",
       "\n",
       "                                             subject  \\\n",
       "0  [September] Exciting days ahead with DataHack ...   \n",
       "1  [Newsletter] Stage for DataHack Summit 2017 is...   \n",
       "\n",
       "                                           email_url  day_of_week  hour  day  \\\n",
       "0  http://r.newsletters.analyticsvidhya.com/7v3rd...            0    19    9   \n",
       "1  http://r.newsletters.analyticsvidhya.com/7vtb2...            5    12   11   \n",
       "\n",
       "   month  IsWeekend  \n",
       "0      1          1  \n",
       "1      2          1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merged.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1010409\n",
       "1      12782\n",
       "Name: is_click, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the the spread of target classes\n",
    "train_merged.is_click.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Danger of Imbalanced Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count of target class 0 is predominant over target class 1, any model trying to predict the target class is biased more towards class 0.<br>\n",
    "As a result of this, class 1 predictions also come out as class 0. Standard accuracy no longer reliably measures performance, which makes model training much trickier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Take the necessary features only for modelling\n",
    "feature_cols = train_merged.columns.drop(['id','user_id','send_date','email_body', 'subject', 'email_url','is_open','is_click'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98751487180816788"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.98748621959514926"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First, let's import the Logistic Regression algorithm and the accuracy metric from Scikit-Learn.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# Separate input features (X) and target variable (y)\n",
    "X = train_merged[feature_cols]\n",
    "y = train_merged.is_click\n",
    "\n",
    "#train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "#cross validation\n",
    "logreg = LogisticRegression().fit(x_train,y_train)\n",
    "logreg_score = cross_val_score(logreg, x_train, y_train, cv=10, scoring='accuracy')\n",
    "logreg_score.mean() #training accuracy\n",
    "\n",
    "# Predict on training set\n",
    "y_pred = logreg.predict(x_test)\n",
    " \n",
    "# How's our accuracy?\n",
    "metrics.accuracy_score(y_test, y_pred) # testing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, many machine learning algorithms are designed to maximize overall accuracy by default.<br>\n",
    "So our model has 98% overall accuracy, but is it because it is predicting only 1 class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Is our model still predicting just one class?\n",
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this model is only predicting class 0, which means it's completely ignoring the minority class in favor of the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with imbalanced datasets entails strategy of balancing classes in the training data (data preprocessing) before providing the data as input to the machine learning algorithm.\n",
    "\n",
    "The main objective of balancing classes is to either increasing the frequency of the minority class or decreasing the frequency of the majority class. This is done in order to obtain approximately the same number of instances for both the classes. Let us look at a few resampling techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Over-Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramdon over-sampling is the process of randomly duplicating observations from the minority class in order to reinforce its signal. There are several heuristics for doing so, but the most common way is to simply resample with replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = train_merged[train_merged.is_click==0]\n",
    "df_minority = train_merged[train_merged.is_click==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1010409\n",
       "0    1010409\n",
       "Name: is_click, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample #import the resampling module from Scikit-Learn\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,                               # sample with replacement\n",
    "                                 n_samples=len(df_majority),    # to match majority class\n",
    "                                 random_state=123)                           # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df_upsampled.is_click.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the new upsampled DataFrame has more observations than the original, and the ratio of the two classes is now 1:1.<br>\n",
    "Now, lets train the upsampled data using Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54581611753134363"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.54645935808236257"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate input features (X) and target variable (y)\n",
    "y = df_upsampled.is_click\n",
    "X = df_upsampled[feature_cols]\n",
    "\n",
    "#train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "#cross validation\n",
    "logreg1 = LogisticRegression().fit(x_train,y_train)\n",
    "logreg1_score = cross_val_score(logreg1, x_train, y_train, cv=10, scoring='accuracy')\n",
    "logreg1_score.mean() # training accuracy\n",
    "\n",
    "#prediction on test data\n",
    "y_pred = logreg1.predict(x_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if our model is still predicting one class\n",
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(1, 285910), (0, 219295)])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_pred).items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model is no longer predicting just one class while the accuracy also is more meaningful now as an evaluation metric.<br>\n",
    "But for this hackathon, the evaluation metric is AOC_RUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57835772890656112"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict probability of train data and compare with test data\n",
    "y_pred = logreg1.predict_proba(x_test)\n",
    "metrics.roc_auc_score(y_test,y_pred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Under-Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Under-Sampling involves randomly removing observations from the majority class to prevent its signal from dominating the learning algorithm. The most common heuristic for doing so is resampling without replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12782\n",
       "0    12782\n",
       "Name: is_click, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,                   # sample without replacement\n",
    "                                 n_samples=len(df_minority),      # to match minority class\n",
    "                                 random_state=123)                # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    " \n",
    "# Display new class counts\n",
    "df_downsampled.is_click.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57306561014374335"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.58434883986042829"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Again apply Logistic Regression model on downsampled data\n",
    "\n",
    "y = df_downsampled.is_click\n",
    "X = df_downsampled[feature_cols]\n",
    "\n",
    "#train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "#cross validation\n",
    "logreg2 = LogisticRegression().fit(x_train,y_train)\n",
    "logreg2_score = cross_val_score(logreg2, x_train, y_train, cv=10, scoring='roc_auc')\n",
    "logreg2_score.mean()\n",
    "\n",
    "#prediction on test data\n",
    "y_pred = logreg2.predict_proba(x_test)\n",
    "metrics.roc_auc_score(y_test, y_pred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Down sampling of the data is giving good roc_auc score than Up sampling the data.<br>\n",
    "Let us try more advanced sampling methods and check for improvement of roc_auc score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE - Synthetic Minority Over-sampling Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique is followed to avoid overfitting which occurs when exact replicas of minority instances are added to the main dataset. A subset of data is taken from the minority class as an example and then new synthetic similar instances are created. These synthetic instances are then added to the original dataset. The new dataset is used as a sample to train the classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Take independent features into x and depenent feature into y\n",
    "x = train_merged[feature_cols]\n",
    "y = train_merged.is_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, 1010409), (1, 1010409)])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE()\n",
    "x_res, y_res = sm.fit_sample(x, y)\n",
    "Counter(y_res).items() #To print value counts of target classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1515613, 11)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(505205, 11)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1515613,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(505205,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_res, y_res)\n",
    "x_train.shape\n",
    "x_test.shape\n",
    "y_train.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57667426285942702"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.57650612027061232"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply Logistic Regression model on data upsampled using SMOTE\n",
    "\n",
    "#cross validation\n",
    "logreg3 = LogisticRegression().fit(x_train,y_train)\n",
    "logreg3_score = cross_val_score(logreg3, x_train, y_train, cv=10, scoring='roc_auc')\n",
    "logreg3_score.mean()\n",
    "\n",
    "#prediction on test data\n",
    "y_pred = logreg3.predict_proba(x_test)\n",
    "metrics.roc_auc_score(y_test, y_pred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC_AUC score of SMOTE is slightly lesser than Random Under-Sampling ROC_AUC score of 0.58434883986042829"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADASYN - Adaptive Synthetic Sampling Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of ADASYN algorithm is to improve class balance by synthetically creating new examples from the minority class via linear interpolation between existing minority class examples. This approach by itself is known as SMOTE method (Synthetic Minority Oversampling TEchnique). ADASYN is an extension of SMOTE, creating more examples in the vicinity of the boundary between the two classes than in the interior of the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, 1010409), (1, 1007333)])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN #import ADASYN package from imblearn.over_sampling\n",
    "from collections import Counter \n",
    "x_res, y_res = ADASYN().fit_sample(x, y)\n",
    "Counter(y_res).items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1513306, 11)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(504436, 11)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1513306,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(504436,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_res, y_res)\n",
    "x_train.shape\n",
    "x_test.shape\n",
    "y_train.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57537144176039556"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.57536879432242283"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply Logistic Regression model on data over-sampled using ADASYN\n",
    "\n",
    "#cross validation\n",
    "logreg4 = LogisticRegression().fit(x_train,y_train)\n",
    "logreg4_score = cross_val_score(logreg4, x_train, y_train, cv=10, scoring='roc_auc')\n",
    "logreg4_score.mean()\n",
    "\n",
    "#prediction on test data\n",
    "y_pred = logreg4.predict_proba(x_test)\n",
    "metrics.roc_auc_score(y_test, y_pred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC_AUC score of ADASYN is slightly lesser than Random Under-Sampling ROC_AUC score of 0.58434883986042829"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble of Samplers - EasyEnsemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EasyEnsemble creates an ensemble of data set by randomly under-sampling the original set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, 12782), (1, 12782)])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.ensemble import EasyEnsemble #import EasyEnsemble package from imblearn.ensemble\n",
    "x_res, y_res = EasyEnsemble().fit_sample(x, y)\n",
    "Counter(y_res[0]).items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19173, 11)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6391, 11)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(19173,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6391,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_res[0], y_res[0])\n",
    "x_train.shape\n",
    "x_test.shape\n",
    "y_train.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.572294328023504"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.57374436369740278"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross validation\n",
    "logreg5 = LogisticRegression().fit(x_train,y_train)\n",
    "logreg5_score = cross_val_score(logreg5, x_train, y_train, cv=10, scoring='roc_auc')\n",
    "logreg5_score.mean()\n",
    "\n",
    "#prediction on test data\n",
    "y_pred = logreg5.predict_proba(x_test)\n",
    "metrics.roc_auc_score(y_test, y_pred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC_AUC score of EasyEnsemble is slightly lesser than Random Under-Sampling ROC_AUC score of 0.58434883986042829"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble of Samplers - BalanceCascade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BalanceCascade differs from the previous method by using a classifier (using the parameter estimator) to ensure that misclassified samples can again be selected for the next subset. In fact, the classifier play the role of a “smart” replacement method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, 12782), (1, 12782)])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.ensemble import BalanceCascade #import BalanceCascade package from imblearn.ensemble\n",
    "bc = BalanceCascade(estimator=LogisticRegression())\n",
    "x_res, y_res = bc.fit_sample(x, y)\n",
    "Counter(y_res[0]).items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19173, 11)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6391, 11)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(19173,)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6391,)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_res[0], y_res[0])\n",
    "x_train.shape\n",
    "x_test.shape\n",
    "y_train.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57810171672976129"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.57246687815804653"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross validation\n",
    "logreg6 = LogisticRegression().fit(x_train,y_train)\n",
    "logreg6_score = cross_val_score(logreg6, x_train, y_train, cv=10, scoring='roc_auc')\n",
    "logreg6_score.mean()\n",
    "\n",
    "#prediction on test data\n",
    "y_pred = logreg6.predict_proba(x_test)\n",
    "metrics.roc_auc_score(y_test, y_pred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC_AUC score of BalanceCascade is slightly lesser than Random Under-Sampling ROC_AUC score of 0.58434883986042829"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble of Samplers - BalancedBaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BalancedBaggingClassifier allows to resample each subset of data before to train each estimator of the ensemble. In short, it combines the output of an EasyEnsemble sampler with an ensemble of classifiers (i.e. BaggingClassifier). Therefore, BalancedBaggingClassifier takes the same parameters as the scikit-learn BaggingClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58968331422425724"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.59995108831399091"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "\n",
    "bbc = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                                ratio='auto',\n",
    "                                replacement=False,\n",
    "                                random_state=0).fit(x_train, y_train)\n",
    "#cross-validation\n",
    "bbc_score = cross_val_score(bbc, x_train, y_train, cv=10, scoring='roc_auc')\n",
    "bbc_score.mean()\n",
    "\n",
    "#predict on test data\n",
    "y_pred = bbc.predict_proba(x_test)\n",
    "metrics.roc_auc_score(y_test,y_pred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC_AUC score of BalancedBaggingClassifier is slightly higher than Random Under-Sampling ROC_AUC score of 0.58434883986042829"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
